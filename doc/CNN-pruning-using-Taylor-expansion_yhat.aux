\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\zref@newlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand*\HyPL@Entry[1]{}
\citation{DLSurvey2019Jiao}
\citation{RCNN}
\citation{MaskRCNN2020He}
\citation{redmon2017yolo9000}
\citation{VGG_Simonyan15}
\citation{ResNet_He_2016_CVPR}
\citation{NIPS2012_4824}
\citation{redmon2017yolo9000}
\citation{Hinton2012dropout}
\citation{pmlr-v28-wan13}
\citation{WU20151}
\citation{conf/cvpr/LiuWFTP15}
\citation{DBLP:journals/corr/abs-1802-10280}
\citation{NIPS2016_6504}
\citation{mitsuno2020hierarchical}
\citation{MolchanovTKAK17}
\HyPL@Entry{0<</S/D>>}
\newlabel{firstpage}{{}{1}{}{Doc-Start}{}}
\@writefile{toc}{\contentsline {section}{\tocsection {}{1}{مقدمه}}{1}{section.1}\protected@file@percent }
\zref@newlabel{footdir@1}{\abspage{1}}
\citation{VGG_Simonyan15}
\citation{VGG_Simonyan15}
\citation{MolchanovTKAK17}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces  معماری مدل \lr {VGG16} \cite  {VGG_Simonyan15} با بیش از ۱۳۰ میلیون پارامتر (وزن). ورودی شبکه، یک تصویر و خروجی آن مشخص‌کننده‌ی طبقه‌ی تصویر ورودی است. }}{2}{figure.1}\protected@file@percent }
\newlabel{fig:vgg16}{{1}{2}{معماری مدل \lr {VGG16} \cite {VGG_Simonyan15} با بیش از ۱۳۰ میلیون پارامتر (وزن). ورودی شبکه، یک تصویر و خروجی آن مشخص‌کننده‌ی طبقه‌ی تصویر ورودی است}{figure.1}{}}
\zref@newlabel{footdir@2}{\abspage{2}}
\@writefile{toc}{\contentsline {section}{\tocsection {}{2}{مروری بر شبکه‌های عصبی}}{3}{section.2}\protected@file@percent }
\newlabel{sec:NN}{{2}{3}{مروری بر شبکه‌های عصبی}{section.2}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{2.1}{مدل پرسپترون}}{3}{subsection.2.1}\protected@file@percent }
\zref@newlabel{footdir@3}{\abspage{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces مدل پرسپترون برای ترکیب عطفی $x_1$ و $x_2$؛ نمایش‌دهنده‌ی خط جداساز شکل \ref  {fig:OR-plot} است.}}{4}{figure.4}\protected@file@percent }
\newlabel{fig:perceptron_or}{{4}{4}{مدل پرسپترون برای ترکیب عطفی $x_1$ و $x_2$؛ نمایش‌دهنده‌ی خط جداساز شکل \ref {fig:OR-plot} است}{figure.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces ترکیب عطفی $x_1$ و $x_2$. بالای خط پررنگ، ناحیه‌ای است که $x_1 \wedge x_2$، \lr {True} است.}}{4}{figure.3}\protected@file@percent }
\newlabel{fig:OR-plot}{{3}{4}{ترکیب عطفی $x_1$ و $x_2$. بالای خط پررنگ، ناحیه‌ای است که $x_1 \wedge x_2$، \lr {True} است}{figure.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces مدل پرسپترون}}{4}{figure.2}\protected@file@percent }
\newlabel{fig:perceptron}{{2}{4}{مدل پرسپترون}{figure.2}{}}
\newlabel{eq:missClassification}{{1}{4}{مدل پرسپترون}{equation.2.1}{}}
\newlabel{eq:noronIn}{{2}{4}{مدل پرسپترون}{equation.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces شبکه عصبی پرسپترون چند لایه}}{5}{figure.5}\protected@file@percent }
\newlabel{fig:MLP}{{5}{5}{شبکه عصبی پرسپترون چند لایه}{figure.5}{}}
\newlabel{sec:learning}{{2.2}{5}{روال آموزش پرسپترون}{subsection.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{2.2}{روال آموزش پرسپترون}}{5}{subsection.2.2}\protected@file@percent }
\newlabel{eq:SSE}{{5}{5}{روال آموزش پرسپترون}{equation.2.5}{}}
\citation{Rumelhart:1988:LRB}
\newlabel{eq:cost_w}{{6}{6}{روال آموزش پرسپترون}{equation.2.6}{}}
\newlabel{eq:delta_w}{{7}{6}{روال آموزش پرسپترون}{equation.2.7}{}}
\newlabel{eq:partial_e}{{8}{6}{روال آموزش پرسپترون}{equation.2.8}{}}
\newlabel{eq:partial_E}{{9}{6}{روال آموزش پرسپترون}{equation.2.9}{}}
\newlabel{eq:nabla_E}{{10}{6}{روال آموزش پرسپترون}{equation.2.10}{}}
\newlabel{eq:partial_e_gaa}{{11}{6}{روال آموزش پرسپترون}{equation.2.11}{}}
\newlabel{eq:nabla_e_gaa}{{12}{6}{روال آموزش پرسپترون}{equation.2.12}{}}
\newlabel{eq:delta_w_e}{{13}{6}{روال آموزش پرسپترون}{equation.2.13}{}}
\zref@newlabel{footdir@4}{\abspage{6}}
\citation{VGG_Simonyan15}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces مدل شبکه‌ی عصبی پیچشی. عموماً در نمایش شبکه‌های پیچشی از مکعب مستطیل برای نمایش نورون‌ها و از ماتریس (دوبعدی) یا مکعب مستطیل (سه‌بعدی) برای نمایش وزن‌ها استفاده می‌شود. مکعب خاکستری در واقع یک نورون با مدل پرسپترون نمایش داده شده در شکل \ref  {fig:perceptron} است. اتصالات شبکه حکم فیلترهای یک شبکه‌ی پیچشی را دارند. }}{7}{figure.6}\protected@file@percent }
\newlabel{fig:CNN}{{6}{7}{مدل شبکه‌ی عصبی پیچشی. عموماً در نمایش شبکه‌های پیچشی از مکعب مستطیل برای نمایش نورون‌ها و از ماتریس (دوبعدی) یا مکعب مستطیل (سه‌بعدی) برای نمایش وزن‌ها استفاده می‌شود. مکعب خاکستری در واقع یک نورون با مدل پرسپترون نمایش داده شده در شکل \ref {fig:perceptron} است. اتصالات شبکه حکم فیلترهای یک شبکه‌ی پیچشی را دارند}{figure.6}{}}
\newlabel{sec:CNNs}{{2.3}{7}{شبکه‌های عصبی پیچشی}{subsection.2.3}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{2.3}{شبکه‌های عصبی پیچشی }}{7}{subsection.2.3}\protected@file@percent }
\zref@newlabel{footdir@5}{\abspage{7}}
\citation{franoischollet2017learning}
\@writefile{toc}{\contentsline {section}{\tocsection {}{3}{ کاهش حجم شبکه‌های عصبی پیچشی}}{8}{section.3}\protected@file@percent }
\newlabel{sec:model_size_reduction}{{3}{8}{کاهش حجم شبکه‌های عصبی پیچشی}{section.3}{}}
\newlabel{sec:Challenges}{{3.1}{8}{چالش‌ها}{subsection.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{3.1}{چالش‌ها}}{8}{subsection.3.1}\protected@file@percent }
\zref@newlabel{footdir@6}{\abspage{8}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces  خلاصه مدل و پارامترهای مدل \lr {VGG16} نمایش داده شده در شکل \ref  {fig:vgg16} برای یک تصویر ورودی فرضی با ابعاد $224\times 224$. این مدل $134,268,738$ وزن دارد. لایه‌هایی که بدون وزن بوده‌اند نمایش داده نشده‌اند. اعداد پررنگ بیانگر تعداد فیلترهای (مجموعه‌ای از وزن‌ها) آن لایه است. تعداد پارامترها ربطی به طول و عرض تصویر ورودی ندارد. کاهش تعداد اتصالات (پارامترها) برای لایه‌های پیچشی بالای نقطه‌چین انجام خواهد شد. }}{9}{table.1}\protected@file@percent }
\newlabel{tab:VGGModelParameters}{{1}{9}{خلاصه مدل و پارامترهای مدل \lr {VGG16} نمایش داده شده در شکل \ref {fig:vgg16} برای یک تصویر ورودی فرضی با ابعاد $224\times 224$. این مدل $134,268,738$ وزن دارد. لایه‌هایی که بدون وزن بوده‌اند نمایش داده نشده‌اند. اعداد پررنگ بیانگر تعداد فیلترهای (مجموعه‌ای از وزن‌ها) آن لایه است. تعداد پارامترها ربطی به طول و عرض تصویر ورودی ندارد. کاهش تعداد اتصالات (پارامترها) برای لایه‌های پیچشی بالای نقطه‌چین انجام خواهد شد}{table.1}{}}
\citation{MolchanovTKAK17}
\newlabel{sec:model_size_reduction_taylor}{{3.2}{10}{استفاده از بسط تیلور در انتخاب وزن‌ها برای کاهش حجم مدل}{subsection.3.2}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{3.2}{ استفاده از بسط تیلور در انتخاب وزن‌ها برای کاهش حجم مدل}}{10}{subsection.3.2}\protected@file@percent }
\newlabel{eq:minEW}{{14}{10}{استفاده از بسط تیلور در انتخاب وزن‌ها برای کاهش حجم مدل}{equation.3.14}{}}
\newlabel{eq:E_w1_w2}{{18}{11}{استفاده از بسط تیلور در انتخاب وزن‌ها برای کاهش حجم مدل}{equation.3.18}{}}
\newlabel{eq:equality}{{21}{11}{استفاده از بسط تیلور در انتخاب وزن‌ها برای کاهش حجم مدل}{equation.3.21}{}}
\newlabel{eq:minREW}{{22}{11}{استفاده از بسط تیلور در انتخاب وزن‌ها برای کاهش حجم مدل}{equation.3.22}{}}
\@writefile{toc}{\contentsline {section}{\tocsection {}{4}{کاربرد در طبقه‌بندی نقاشی‌های سبک امپرسیونیسم و مینیاتور}}{11}{section.4}\protected@file@percent }
\newlabel{sec:results}{{4}{11}{کاربرد در طبقه‌بندی نقاشی‌های سبک امپرسیونیسم و مینیاتور}{section.4}{}}
\zref@newlabel{footdir@7}{\abspage{11}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces  تصاویر کلود مونه (نقاش با سبک امپرسیونیسم) و محمود فرشچیان (مینیاتور) در کنار برخی از آثار ایشان. }}{12}{figure.7}\protected@file@percent }
\newlabel{fig:MF-images}{{7}{12}{تصاویر کلود مونه (نقاش با سبک امپرسیونیسم) و محمود فرشچیان (مینیاتور) در کنار برخی از آثار ایشان}{figure.7}{}}
\zref@newlabel{footdir@8}{\abspage{12}}
\citation{franoischollet2017learning}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces  خروجی روی ده تصویر آزمون. تصویر اول از سطر دوم، متعلق به سبک مینیاتور بوده است که به اشتباه متعلق به سبک امپرسیونیسم شمرده شده است. }}{13}{figure.8}\protected@file@percent }
\newlabel{fig:output}{{8}{13}{خروجی روی ده تصویر آزمون. تصویر اول از سطر دوم، متعلق به سبک مینیاتور بوده است که به اشتباه متعلق به سبک امپرسیونیسم شمرده شده است}{figure.8}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces مشخصات سیستم گوگل کولب، مورد استفاده در آزمایش‌ها.}}{13}{table.2}\protected@file@percent }
\newlabel{tab:colabSpec}{{2}{13}{مشخصات سیستم گوگل کولب، مورد استفاده در آزمایش‌ها}{table.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces  خلاصه مدل و پارامترهای مدل هرس شده با استفاده از بسط تیلور. هرس وزن‌ها فقط برای لایه‌های بالای نقطه‌چین در این جدول انجام شده است. اتصالات این لایه‌ها نسبت به لایه‌های متناظر در جدول \ref  {tab:VGGModelParameters} نزدیک به ۹۵ درصد کاهش پیدا کرده‌اند. اگر تعداد کل پارامترهای مدل مدنظر باشد، نسبت تعداد پارامترهای این مدل به مدل اولیه $0.17$ است که به منزله‌ی کاهش ۸۳ درصدی می‌باشد. به این ترتیب مدل بسیار کوچکتری حاصل شده است که کارایی کمتری از مدل اولیه ندارد. }}{14}{table.3}\protected@file@percent }
\newlabel{tab:VGG-prunned-ModelParameters}{{3}{14}{خلاصه مدل و پارامترهای مدل هرس شده با استفاده از بسط تیلور. هرس وزن‌ها فقط برای لایه‌های بالای نقطه‌چین در این جدول انجام شده است. اتصالات این لایه‌ها نسبت به لایه‌های متناظر در جدول \ref {tab:VGGModelParameters} نزدیک به ۹۵ درصد کاهش پیدا کرده‌اند. اگر تعداد کل پارامترهای مدل مدنظر باشد، نسبت تعداد پارامترهای این مدل به مدل اولیه $0.17$ است که به منزله‌ی کاهش ۸۳ درصدی می‌باشد. به این ترتیب مدل بسیار کوچکتری حاصل شده است که کارایی کمتری از مدل اولیه ندارد}{table.3}{}}
\@writefile{toc}{\contentsline {section}{\tocsection {}{5}{جمع‌بندی}}{14}{section.5}\protected@file@percent }
\bibstyle{ieeetr-fa}
\bibdata{MyReferences}
\bibcite{DLSurvey2019Jiao}{1}
\bibcite{RCNN}{2}
\bibcite{MaskRCNN2020He}{3}
\bibcite{redmon2017yolo9000}{4}
\bibcite{VGG_Simonyan15}{5}
\bibcite{ResNet_He_2016_CVPR}{6}
\bibcite{NIPS2012_4824}{7}
\bibcite{Hinton2012dropout}{8}
\bibcite{pmlr-v28-wan13}{9}
\@writefile{toc}{\contentsline {section}{\tocsection {}{}{سپاس‌گزاری}}{15}{section*.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\tocsection {}{}{مراجع}}{15}{section*.2}\protected@file@percent }
\bibcite{WU20151}{10}
\bibcite{conf/cvpr/LiuWFTP15}{11}
\bibcite{DBLP:journals/corr/abs-1802-10280}{12}
\bibcite{NIPS2016_6504}{13}
\bibcite{mitsuno2020hierarchical}{14}
\bibcite{MolchanovTKAK17}{15}
\bibcite{Rumelhart:1988:LRB}{16}
\bibcite{franoischollet2017learning}{17}
\newlabel{tocindent-1}{0pt}
\newlabel{tocindent0}{15.36804pt}
\newlabel{tocindent1}{21.83755pt}
\newlabel{tocindent2}{0pt}
\newlabel{tocindent3}{0pt}
\newlabel{lastpage}{{5}{16}{سپاس‌گزاری}{section*.2}{}}
\gdef \@abspage@last{16}
